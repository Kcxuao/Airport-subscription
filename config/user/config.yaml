version: 1.0
telegram:
  token: ""  # 机器人TOKEN
  whiteList: [''] # 白名单

vpn:
  chromePath: Chrome  # 谷歌浏览器可执行文件路径
  ip: 127.0.0.1
  port: 9527
  retry: 20  # 最大重试次数
  urlList:
    [
      {
        name: 'xxx',
        url: 'http://example.com',
      },
    ]
    
vpn2:
  retry: 20
  urlList:
    [
      {
        name: 'xxx',
        url: 'http://example.com',
      },
    ]

webdav:
  uploadPath: /Surfboard/profiles/  # webdav路径
  savePath: files/  # 文件保存路径
  options:
    webdav_hostname: ""  # webdav地址
    webdav_login: ""  # 账号
    webdav_password: ""  # 密码
    disable_check: True

public:

  mode: "surfboard"
  format: ".conf"
  subconverterPath: subconverter/subconverter


openai: 
  api_key: sk-xxx     # openai api_key
  completion_params:
    model: 'text-davinci-003'  # 模型
    temperature: 0.8  # 采样温度，介于 0 和 2 之间。较高的值（如 0.8）将使输出更加随机，而较低的值（如 0.2）将使输出更加集中和确定。
    max_tokens: 2048  # 最大令牌数，您的提示加上的令牌计数max_tokens不能超过模型的上下文长度。大多数模型的上下文长度为 2048 个标记（最新模型除外，它支持 4096）。
    top_p: 1.0 # 一种替代温度采样的方法，称为核采样，其中模型考虑具有 top_p 概率质量的标记的结果。所以 0.1 意味着只考虑构成前 10% 概率质量的标记。
    frequency_penalty: 0.5 # 频率惩罚，-2.0 和 2.0 之间的数字。正值会根据新标记在文本中的现有频率对其进行惩罚，从而降低模型逐字重复同一行的可能性。
    presence_penalty: 0.0  # 存在_惩罚，-2.0 和 2.0 之间的数字。正值会根据到目前为止是否出现在文本中来惩罚新标记，从而增加模型谈论新主题的可能性。

  image_params:
    n: 1  # 返回图片数量
    size: '1024x1024'  # 规格
    # response_format: 'b64_json'  # 默认url

  image_str_list: ['图片', '图', '照片']  # 图片关键词

image:
  # mode: # all | mp | pc | silver | furry | r18 | pixiv | jitsu
  # all: 全部正常图
  # mp: 竖屏壁纸
  # pc: 横屏壁纸
  # silver: 银发
  # furry: 兽耳
  # r18: 无需多说
  # pixiv: p站随机图
  # jitsu: api作者收藏
  mode: r18